---
# Metadaten / meta data
title: "Methodenbaustein Einlesen strukturierter Datensätze"
author:
  - Lukas Arnold
  - Simone Arnold
  - Florian Bagemihl
  - Matthias Baitsch
  - Marc Fehr
  - Maik Poetzsch
  - Sebastian Seipel
date: today # "2024-03-05" Jahr-Monat-Tag / year-month-day

## Spracheinstellungen / language settings
lang: de
language:
  de:
    crossref-imp-title: "Definition"
    crossref-imp-prefix: "Definition"
    crossref-lst-title: "Code-Block"
    crossref-lst-prefix: "Code-Block"
    crossref-nte-title: "Beispiel"
    crossref-nte-prefix: "Beispiel"
    crossref-tip-title: "Tipp"
    crossref-tip-prefix: "Tipp"
    crossref-wrn-title: "Hinweis"
    crossref-wrn-prefix: "Hinweis"

## Formatoption / formating options
format:
  html:
    default-image-extension: svg
    code-copy: true # hover is default
#  pdf:
#    cite-method: biblatex
#    biblio-title: Quellen
#    default-image-extension: pdf # Vektorgrafiken werden als PDF eingebunden / vector grafics are embedded as PDF
execute:
  cache: false # remove when document is finished as cache: true can cause issues from time to time

## Inhaltsverzeichnis / table of contents
toc: true
number-sections: true
number-depth: 2

## Bibliographie / bibliography
bibliography: bibliography.bib
biblio-style: authoryear

## Objekteinstellungen / object options
cap-location: bottom
fig-align: center

### Grafiken von R oder Matplotlib / Figures from R or Matplotlib
# Empfehlung von / suggestion from https://r4ds.hadley.nz/quarto#sec-figures
# fig-width: 6
# fig-asp: 0.618
---

::: {.border #Lizenz}

:::: {layout="[20, 80]"}
![](skript/00-bilder/CC-BY.svg)

Bausteine Computergestützter Datenanalyse von Lukas Arnold, Simone Arnold, Florian Bagemihl, Matthias Baitsch, Marc Fehr, Maik Poetzsch und Sebastian Seipel. Methodenbaustein Einlesen strukturierter Datensätze von Maik Poetzsch ist lizensiert unter [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.de). Das Werk ist abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze). Ausgenommen von der Lizenz sind alle Logos und anders gekennzeichneten Inhalte. 2024

::::

Zitiervorschlag

Arnold, Lukas, Simone Arnold, Matthias Baitsch, Marc Fehr, Maik Poetzsch, und Sebastian Seipel. 2024. „Bausteine Computergestützter Datenanalyse. Methodenbaustein Einlesen strukturierter Datensätze“. <https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze>.

BibTeX-Vorlage

```
@misc{BCD-m-einlesen-strukturierter-datensätze-2024,
 title={Bausteine Computergestützter Datenanalyse. Methodenbaustein Einlesen strukturierter Datensätze},
 author={Arnold, Lukas and Arnold, Simone and Baitsch, Matthias and Fehr, Marc and Poetzsch, Maik and Seipel, Sebastian},
 year={2024},
 url={https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze}} 
```

:::

{{< pagebreak >}}

{{< include _voraussetzungen.md >}}

{{< include _lernziele.md >}}

# Einleitung

Am Beginn der Datenanalyse steht das Einlesen von Daten aus Dateien oder aus Datenbanken, um diese für die Auswertung verfügbar zu machen. In der Praxis ist das Einlesen von Daten alles andere als trivial. 2016 stellte eine Studie fest, dass ein Fünftel aller wissenschaftlichen Artikel im Bereich der Genetik auf der Grundlage von durch die Tabellenkalkulation Excel verfälschten Daten durchgeführt wurde ([@Ziemann-2016]). Genbezeichnungen wie "MARCH1" wurden fälschlicherweise in ein Datumsformat umgewandelt. 2021 wurde diese Schätzung des Anteils betroffener Arbeiten sogar auf 30 Prozent angehoben. ([heise online](https://www.heise.de/news/Excel-wandelt-Genbezeichnungen-in-Datumsangaben-um-Problem-groesser-als-gedacht-6165902.html))

::: {.border layout="[[5, 90, 5], [1], [1]]"}

&nbsp;

“Tidy datasets are all alike, but every messy dataset is messy in its own way.”  Hadley Wickham

&nbsp;

&nbsp;

[@R-for-Data-Science, Kapitel 5 Data tidying]

:::

Häufig werden Daten nicht selbst erstellt, sondern von externen Quellen bezogenen, sodass das Format und der innere Aufbau von Datensätzen nicht selbst bestimmt werden können. Deshalb ist es in der Datenanalyse erforderlich, mit verschiedenen Dateiformaten umgehen zu können: mit wenigen Kilobyte großen Textdateien, proprietären Formaten gängiger Büroanwendungen und mehreren hundert Megabyte großen Dateien in für den Austausch wissenschaftlicher Daten entwickelten Formaten. Programmiersprachen wie Python und R bringen verschiedene Werkzeuge zum Lesen, Bearbeiten und Speichern von verschiedenen Dateiformaten mit, die durch spezialisierte Pakete ergänzt werden können.

Die praktischen Herausforderungen der Datenanalyse beschränken sich jedoch nicht nur auf technische Aspekte. Oftmals bereitet der innere Aufbau von Datensätzen die größten Schwierigkeiten. Dasu und Johnson schreiben: 

::: {.border layout="[[5, 90, 5], [1], [1]]"}

&nbsp;

"Unfortunately, the data set is usually dirty, composed of many tables, and has unknown properties. Before any results can be produced, the data must be cleaned and explored—often a long and
difficult task. [...] In our experience, the tasks of exploratory data mining and data cleaning constitute 80% of the effort that determines 80% of the value of the ultimate data
mining results."

&nbsp;

&nbsp;

([@Dasu-Johnson-2003], S. ix)

:::

Ein wichtiger Bestandteil des Einlesens strukturierter Datensätze besteht deshalb darin, Fehler im Datensatz zu suchen und ggf. zu bereinigen. Unter dem Begriff des Einlesens strukturierter Datensätze wird der gesamte Prozess des Einlesens, der Fehlersuche und -korrektur und des Abspeicherns in für die weitere Bearbeitung geeigneter Form gefasst.

# Grundlagen: Merkmale von Datensätzen
Bevor wir uns mit den praktischen Herausforderungen des Einlesens strukturierter Datensätze beschäftigten, werden zunächst einige Merkmale von Datensätzen diskutiert, um ein grundlegendes Verständnis der Begrifflichkeiten zu schaffen **und den Umgang der in der Basis von Python bzw. R enthaltenen Werkzeuge zu vermitteln**.

::: {#imp-Datensatz .callout-important}
## Datensatz

Ein Datensatz ist eine Sammlung zusammengehöriger Daten. Datensätze enthalten einer oder mehreren Variablen zugeordnete Werte. Jeder Datensatz besitzt ein technisches Format, eine Struktur, mindestens eine Variable und mindestens einen Wert.

:::

## Technisches Format
Das technische Format gibt vor, mit welchen Mitteln Daten eingelesen, bearbeitet und gespeichert werden können. Einige Beispiele sind:

  - Druckerzeugnis, z. B. Telefonbuch: manuelles Ablesen von Name und Telefonnummer, irreversible Bearbeitung per Stift
  
  - Lochkarte, z. B. Parkschein: Lesegerät erkennt Lochung und gewährt eine Freistunde, irreversible Bearbeitung mit Stanzgerät
  
  - Textdatei, z. B. Einwohnerzahl nach Bundesländern: Kann mit einer Vielzahl von Computerprogrammen wie Texteditor, Tabellenkalkulationsprogramm oder Programmierumgebung eingelesen, bearbeitet und gespeichert werden.
  
  - Hierarchical Data Format HDF5, z. B. räumliche Daten zur Blitzdichte: benötigt spezialisierte Programme oder Pakete

## Struktur
Datensätze speichern Daten in einer definierten n-dimensionalen Struktur.

::: {.border}
![n-dimensionale Datensätze](skript/00-bilder/slicing_mf_mp.png){fig-alt="Dargestellt sind von links nach rechts ein-, zwei- und dreidimensionale Blockstrukturen, die Datensätze repräsentieren. Die Teilgrafiken werden in den folgenden Abschnitten wiederverwendet und dabei auch näher beschrieben."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). 2024
:::

### Eindimensionale Datensätze
Die einfachste Form sind eindimensionale Datensätze, die in einer **Liste** Werte einer einzigen Variablen zuordnen. Eindimensionale Datensätze verfügen lediglich über eine Achse: den Index, über den Elemente angesprochen werden können.

::: {.border}

![eindimensionale Datensätze](skript/00-bilder/eindimensionaler-datensatz-slicing-mf-mp.png){width="50%" fig-alt="Dargestellt ist ein in fünf Blöcke unterteilter Streifen, der einen eindimensionalen Datensatz repräsentiert. Die Blöcke sind entlang der 0. Achse von links nach rechts mit 0 bis 4 beschriftet. Von Block Null aus geht ein blauer Pfeil zu Block drei, der blau markiert ist."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024
:::

&nbsp;

Beispiele eindimensionaler Datensätze sind ein Einkaufszettel oder die Urliste eines Würfelexperiments. Über den Index kann beispielsweise das Würfelergebnis an der Indexposition 2 ausgegeben werden.

``` {python}
print( *( Augen := [6, 2, 1, 2] ) )

print(f"Das Würfelergebnis an Indexposition 2 lautet: {Augen[2]}")
```


### Übung: eindimensionale Daten einlesen mit Python

**Maya und Hans haben je sechs Mal einen Würfel geworfen und ihre Wurfergebnisse in einer .txt-Datei protokolliert. Sie sollen die Dateien auswerten, um zu bestimmen, wer von beiden in Summe die höchste Augenzahl erreicht hat.**

| Daten | Dateiname |
|---|------|
| Würfelergebnisse Maya | dice-maya.txt |
| Würfelergebnisse Hans | dice-hans.txt|

&nbsp;

{{< include _dateien-einlesen-mit-python.md >}}


**Welche Augenzahl hat Hans erreicht?**

**Die Musterlösung kann Marc machen**

### Zweidimensionale Datensätze
Zweidimensionale Datensätze organisieren Werte in einer aus Zeilen und Spalten bestehenden **Matrix**.

::: {.border}
![zweidimensionaler Datensatz](skript/00-bilder/zweidimensionaler-datensatz-slicing-mf-mp.png){width="45%" fig-alt="Dargestellt ist ein zweidimensionaler Block, der einen zweidimensionalen Datensatz repräsentiert. Pfeile repräsentieren die zwei Achsen. Die nullte Achse entspricht der Länge (von oben nach unten) und die erste Achse der Breite des Datensatzes."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024
:::

&nbsp;

Die meisten Datensätze sind zweidimensional. Typischerweise entspricht jede Spalte einer **Variablen**, und jede Zeile einer **Beobachtung**. Variablen speichern alle Werte eines Merkmals, zum Beispiel des Würfelergebnisses. Beobachtungen speichern alle Werte, die für eine Beobachtungseinheit gemessen wurden, z. B. für eine Person. [@Wickham-2014, S. 3]

``` {python}
import pandas as pd

messung1 = pd.DataFrame({'Name': ['Hans', 'Elke', 'Jean', 'Maya'], 'Geburtstag': ['26.02.', '14.03.', '30.12.', '07.09.'], 'Würfelfarbe': ['rosa', 'rosa', 'blau', 'gelb'], 'Summe Augen': [17, 12, 8, 23]})

messung1
```

&nbsp;

Über die Angabe der Indizes entlang der 0. und der 1. Achse kann die Summe der gewürfelten Augen einer Person ausgegeben werden. 

``` {python}

print(f"Jean würfelte {messung1.iloc[2, 3]} Augen")
```

Es ist aber auch möglich, zunächst eine Spalte auszuwählen und dann wie bei einem eindimensionalen Datensatz den Wert an einer Indexposition aufzurufen.

``` {python}

print(f"Jean würfelte {messung1['Summe Augen'][2]} Augen")
```

### long- und wide-Format
Zweidimensionale Datensätze werden zumeist in einer aus Zeilen und Spalten bestehenden Matrix dargestellt. Den zeilenweise eingetragenen Beobachtungen werden Werte für die in den Spalten organisierten Variablen zugeordnet. Diese Art Daten darzustellen, wird wide-Format genannt: Mit jeder zusätzlich gemessenen Variablen wird der Datensatz breiter.

Eine andere Art Daten zu organisieren und über Daten nachzudenken, ist die Darstellung im long-Format. Einige Programme und Pakete erfordern Daten im long-Format oder profitieren zumindest davon beispielsweise bei der Erstellung von Grafiken. Schauen wir uns zunächst noch einmal den Datensatz messung1 im wide-Format an. Welche Beobachtungseinheiten gibt es? Welche Variablen wurden für diese erhoben?

``` {python}
#| echo: false

messung1
```

&nbsp;

Vermutlich werden Sie davon ausgehen, dass die Beobachtungseinheiten Hans, Elke, Jean und Maya sind und die Variablen Geburtstag, Würfelfarbe und Summe Augen. Es ist aber auch denkbar, dass die Beobachtungseinheit Person mit 0, 1, 2 und 3 kodiert wurde (dem Zeilenindex des Datensatzes) und die Spalte Name ebenfalls eine der erhobenen Variablen ist. Ebenso könnte es nur zwei Variablen, Würfelfarbe und Summe Augen, geben, während die Spalten Name und Geburtstag die beobachteten Personen kodieren. Stellen Sie sich vor, eine zweite Person mit dem Namen Hans hätte auch gewürfelt. Dann könnten die Würfelergebnisse der Personen mit dem Namen Hans könnten nur über den Geburtstag am 26.02. oder 11.11. korrekt zugeordnet werden.

``` {python}
messung1 = pd.DataFrame({'Name': ['Hans', 'Elke', 'Jean', 'Maya', 'Hans'], 'Geburtstag': ['26.02.', '14.03.', '30.12.', '07.09.', '11.11.'], 'Würfelfarbe': ['rosa', 'rosa', 'blau', 'gelb', 'rosa'], 'Summe Augen': [12, 17, 8, 23, 7]})

messung1
```

&nbsp;

Das long-Format macht diese Überlegungen explizit, indem identifizierende Variablen (identification variables, kurz: id vars) und gemessene Variablen (measure variables, kurz: measure vars oder value vars) unterschieden werden. Die Transformation eines Datensatzes aus dem wide-Format ins long-Format wird melting (schmelzen) genannt. Das Modul Pandas bietet die Funktion `pd.melt(frame, id_vars = None)`. Diese erwartet einen DataFrame. Im optionalen Argument `id_vars` wird angegeben, welche Spalten die identifizierenden Variablen sind.

``` {python}

messung1_long = pd.melt(messung1, id_vars = ['Name', 'Geburtstag'])

messung1_long
```

&nbsp;

Im long-Format werden die gemessenen Variablen in der Spalte variable aufgeführt und deren Wert in der Spalte value eingetragen. Mit jeder zusätzlich erhobenen Variablen wird der Datensatz länger.

Wenn Sie die Unterscheidung von identifizierenden und gemessenen Variablen zu Ende denken, kann der Variablenname selbst als eine identifizierende Variable für den Wert in der Spalte value aufgefasst werden. Ein Datensatz kann als eine Struktur verstanden werden, die genau eine gemessene Variable, nämlich value, und eine Anzahl identifizierender Variablen besitzt. Dies kann im long-Format wie folgt dargestellt werden.

``` {python}
#| output: false

messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe'])

messung1_all_id

```

::: {layout="[70, 30]"}
``` {python}
#| echo: false

messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe'])

messung1_all_id

```

![](skript/00-bilder/5f489ffabc91dec1ec2192dc4e993e00.jpg){width="90%"} 

<!-- wow kommt wieder weg ;-) -->

::: 

Auch der umgekehrte Fall ist möglich: Werden beim melting keine id_vars angegeben, werden alle Spalten als gemessene Variablen behandelt.

``` {python}

messung1_no_id = pd.melt(messung1)

messung1_no_id

```

&nbsp;

Die Umkehroperation zum melting wird casting (gießen) oder pivoting (schwenken) genannt. Dabei wird ein im long-Format vorliegender Datensatz in das wide-Format konvertiert. Die Pandas Funktion `pd.pivot(data, columns, index)` nimmt einen melted DataFrame entgegen und konveriert diesen aus den einzigartigen Werten in columns (= Spaltennamen des DataFrame im wide-Format) und den einzigartigen Werten in index (= Zeilenindex des DataFrame im wide-Format). Wird keine Spalte für index übergeben, wird der bestehende Index des melted DataFrame verwendet (der mit 20 Zeilen natürlich viel zu lang ist.) Da das Objekt messung1_no_id keine geeignete Indexspalte besitzt, muss diese vor dem casting erzeugt werden. Dies ist mit der Methode `messung1_no_id.groupby('variable').cumcount()` möglich, die die Anzahl jeder Ausprägung in der übergebenen Spalte bei 0 beginnend durchzählt. (Ein direktes Ersetzen des Index ist auf diese Weise nicht möglich, da der Index des an `pd.pivot(data, columns, index)` übergebenen DataFrame keine Doppelungen enthalten darf.)

``` {python}
# pd.pivot() benötigt einen Index oder benutzt den bestehenden Index, des melted_df, der zu lang ist
# Deshalb eine zusätzliche Spalte in messung1_no_id einfügen
## 'händisch': messung1_no_id['new_index'] = list(range(0, 5)) * 4 
## allgemein: messung1_no_id['new_index'] = messung1_no_id.groupby('variable').cumcount()

# Spalte new_index einfügen
messung1_no_id['new_index'] = messung1_no_id.groupby('variable').cumcount()
print (f"Der Datensatz im long-Format mit zusätzlicher Spalte:\n{messung1_no_id}")

# casting
messung1_cast = pd.pivot(messung1_no_id, index = 'new_index', columns = 'variable', values = 'value')
print(f"\nDer Datensatz im wide-Format:\n{messung1_cast}")

# Spalten anordnen, Index zurücksetzen
messung1_cast = messung1_cast[['Name', 'Geburtstag', 'Würfelfarbe', 'Summe Augen']]
messung1_cast.reset_index(drop = True, inplace = True)
messung1_cast.rename_axis(None, axis = 1, inplace = True)

print(f"\nDer Datensatz im wide-Format mit zurückgesetztem Index:\n\n{messung1_cast}")
```

&nbsp;

### Übung: zweidimensionale Daten im long- und wide-Format
Oben wurde das Objekt messung_long mit dem Befehl `messung1_long = pd.melt(messung1, id_vars = ['Name', 'Geburtstag'])` angelegt. **Benutzen Sie die Methode** `df.cast()`, **um den Datensatz messung1 wieder ins wide-Format zu transformieren.**

``` {python}
#| echo: false

messung1_long
```


:::{#tip-pivoting .callout-tip collapse="true"}
## Musterlösung zweidimensionale im long- und wide-Format

``` {python}

# Spalte new_index einfügen
messung1_long['new_index'] = messung1_long.groupby('variable').cumcount()

# casting
messung1_long_cast = pd.pivot(messung1_long, index = 'new_index', columns = 'variable', values = 'value')

# Spalten anordnen, Index zurücksetzen
messung1_long_cast = messung1_cast[['Name', 'Geburtstag', 'Würfelfarbe', 'Summe Augen']]
messung1_long_cast.reset_index(drop = True, inplace = True)
messung1_long_cast.rename_axis(None, axis = 1, inplace = True)

messung1_long_cast

```


:::

### Drei- und mehrdimensionale Datensätze
Datensätze können auch drei- oder mehrdimensional aufgebaut sein.

::: {.border}

![dreidimensionale Datensätze](skript/00-bilder/dreidimensionaler-datensatz-slicing-mf-mp.png){width="50%" fig-alt="Dargestellt ist ein dreidimensionaler Block, der einen dreidimensionalen Datensatz repräsentiert. Pfeile repräsentieren die drei Achsen. Die nullte Achse entspricht der Tiefe, die erste Achse der Länge (von oben nach unten) und die zweite Achse der Breite des Datensatzes."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024
:::

&nbsp;

hierhier: Beispiele für drei- und mehrdimensionale Daten.

Mehrdimensional: z. B. Messung an verschiedenen Zeitpunkten oder an verschiedenen Orten
2 Tabellen nebeneinander: Würfelergebnisse und eine Würfelfarbe haben sich geändert



::: {layout-ncol="[50, -10, 50]"}

| Messung 1 | Geburtstag | Würfelfarbe | Summe Augen |
|----|------|------|------|
|  Hans | 26.02. | rosa | 12 |
| Elke | 14.03. | rosa | 22 |
| Jean | 30.12. | blau | 8 |
| Maya | 07.09. | gelb | 17 |

| Messung 2 | Geburtstag | Würfelfarbe | Summe Augen |
|----|------|------|------|
|  Hans | 26.02. | rosa | 14 |
| Elke | 14.03. | rosa | 9 |
| Jean | 30.12. | rosa | 21 |
| Maya | 07.09. | gelb | 13 |

:::

Wir können uns eine vierte Dimension für diese Daten vorstellen, die die Person codiert, die die Messung beaufsichtigt und den Teildatensatz erstellt hat.
Format, Struktur, Variablen, Werte.

Format und Struktur: Unterschied

Kasten Unterschied Format und Struktur, sieht man gut am long- und wide-Format --> potenzielle Begriffskollission zwischen technischem Format und long- und wide-Format

Hinweiskasten zum Unterschied von Format und Struktur
Datensätze unterscheiden sich hinsichtlich ihres Formats (Format unterscheidet sich von Dimensionalität dadurch: Ein dreidimensionaler Datensatz kann in einer Tabellenkalkulation gespeichert in Form einer Matrix (dim = 2) gespeichert werden, die dritte Dimension wird über die Anzahl der Tabellenblätter abgebildet. Es ist aber auch möglich, dreidimensionale Daten in einer einfachen Textdatei zu speichern. data =[ [[1, 2, 3], [2, 3, 1], [3, 2, 1]], [Liegestütze, Kniebeuge, Hock-Streck-Sprünge], [morgens, mittags, abends], [Claus, Petra, Hans]]), ihrer Struktur, d


# Struktur
Datensätze sind Objekte mit einer definierten Struktur. 1-dimensional, 2-dimensional, mehrdimensional

# Datentyp
numerisch, character, factor, boolean, datetime usw. ... 

# Metadaten

# fehlende Werte
nix, NA, NaN, --, -1

masked Arrays

eindimensionaler Datensatz: Urliste von Ergebnissen eines Münzwurfs.
Woraus besteht ein Datensatz?

Dazu gehört die Trennung von Rohdaten, Metadaten, Grafiken und anderer gestalterische Elemente. 

disziplinäre Konventionen und persönliche Vorlieben (z. B. zur Kennzeichnung fehlender oder ungültiger Werte)
ein "NA" führt leicht dazu, dass ein numerischer Datensatz als Zeichenkette erkannt wird.


# Strategien der Fehlersuche und Bereinigung

::: {.border layout="[[5, 90, 5], [1], [1]]"}

&nbsp;

"everybody I know has war stories about cleaning up lousy datasets"  
Nicholas J. Cox

&nbsp;

&nbsp; 

Cox, Nicholas J. 2004: Exploratory Data Mining and Data Cleaning. Book Review 9. In: Journal of Statistical Software 2004, Volume 11. <https://www.jstatsoft.org/article/view/v011b09/30>

:::

# Programme
https://www.heise.de/news/Excel-wandelt-Genbezeichnungen-in-Datumsangaben-um-Problem-groesser-als-gedacht-6165902.html

# Pfade
Dateipfad feststellen (lokal, im Internet), durch Verzeichnisse navigieren 

  * slash / und backslash nach Betriebssystem (Win, Linux, Mac) und Programmiersprache (Python und R)

* Inhalt (gerne abwechslungsreich gestalten)

  * Theorie

  * Beispiele

  * Übungen

# Das Wichtigste (vielleicht als Video)

# Lernzielkontrolle

  * Kompetenzquiz (ggf. aufklappbarer Callout Block, Textverweis für PDF, polierte Lösungen evntl. via Lumi später entscheiden)

  * Übungsaufgaben (kleine Projekte)

* Prüfungsaufgaben (ohne Lösungen)
