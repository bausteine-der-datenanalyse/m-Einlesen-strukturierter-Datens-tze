---
# Metadaten / meta data
title: "Methodenbaustein Einlesen strukturierter Datensätze"
author:
  - Lukas Arnold
  - Simone Arnold
  - Florian Bagemihl
  - Matthias Baitsch
  - Marc Fehr
  - Maik Poetzsch
  - Sebastian Seipel
date: today # "2024-03-05" Jahr-Monat-Tag / year-month-day

## Spracheinstellungen / language settings
lang: de
language:
  de:
    crossref-imp-title: "Definition"
    crossref-imp-prefix: "Definition"
    crossref-lst-title: "Code-Block"
    crossref-lst-prefix: "Code-Block"
    crossref-nte-title: "Beispiel"
    crossref-nte-prefix: "Beispiel"
    crossref-tip-title: "Tipp"
    crossref-tip-prefix: "Tipp"
    crossref-wrn-title: "Hinweis"
    crossref-wrn-prefix: "Hinweis"

## Formatoption / formating options
format:
  html:
    default-image-extension: svg
    code-copy: true # hover is default
#  pdf:
#    cite-method: biblatex
#    biblio-title: Quellen
#    default-image-extension: pdf # Vektorgrafiken werden als PDF eingebunden / vector grafics are embedded as PDF
execute:
  cache: false # remove when document is finished as cache: true can cause issues from time to time

## Inhaltsverzeichnis / table of contents
toc: true
number-sections: true
number-depth: 2

## Bibliographie / bibliography
bibliography: bibliography.bib
biblio-style: authoryear

## Objekteinstellungen / object options
cap-location: bottom
fig-align: center

### Grafiken von R oder Matplotlib / Figures from R or Matplotlib
# Empfehlung von / suggestion from https://r4ds.hadley.nz/quarto#sec-figures
# fig-width: 6
# fig-asp: 0.618
---

::: {.border #Lizenz}

:::: {layout="[20, 80]"}
![](skript/00-bilder/CC-BY.svg)

Bausteine Computergestützter Datenanalyse von Lukas Arnold, Simone Arnold, Florian Bagemihl, Matthias Baitsch, Marc Fehr, Maik Poetzsch und Sebastian Seipel. Methodenbaustein Einlesen strukturierter Datensätze von Maik Poetzsch ist lizensiert unter [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.de). Das Werk ist abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze). Ausgenommen von der Lizenz sind alle Logos und anders gekennzeichneten Inhalte. 2024

::::

Zitiervorschlag

Arnold, Lukas, Simone Arnold, Matthias Baitsch, Marc Fehr, Maik Poetzsch, und Sebastian Seipel. 2024. „Bausteine Computergestützter Datenanalyse. Methodenbaustein Einlesen strukturierter Datensätze“. <https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze>.

BibTeX-Vorlage

```
@misc{BCD-m-einlesen-strukturierter-datensätze-2024,
 title={Bausteine Computergestützter Datenanalyse. Methodenbaustein Einlesen strukturierter Datensätze},
 author={Arnold, Lukas and Arnold, Simone and Baitsch, Matthias and Fehr, Marc and Poetzsch, Maik and Seipel, Sebastian},
 year={2024},
 url={https://github.com/bausteine-der-datenanalyse/m-Einlesen-strukturierter-Datens-tze}} 
```

:::

{{< pagebreak >}}

{{< include _voraussetzungen.md >}}

{{< include _lernziele.md >}}

# Einleitung

Am Beginn der Datenanalyse steht das Einlesen von Daten aus Dateien oder aus Datenbanken, um diese für die Auswertung verfügbar zu machen. In der Praxis ist das Einlesen von Daten alles andere als trivial. 2016 stellte eine Studie fest, dass ein Fünftel aller wissenschaftlichen Artikel im Bereich der Genetik auf der Grundlage von durch die Tabellenkalkulation Excel verfälschten Daten durchgeführt wurde ([@Ziemann-2016]). Genbezeichnungen wie "MARCH1" wurden fälschlicherweise in ein Datumsformat umgewandelt. 2021 wurde diese Schätzung des Anteils betroffener Arbeiten sogar auf 30 Prozent angehoben. ([heise online](https://www.heise.de/news/Excel-wandelt-Genbezeichnungen-in-Datumsangaben-um-Problem-groesser-als-gedacht-6165902.html))

::: {.border layout="[[5, 90, 5], [1], [1]]"}

&nbsp;

“Tidy datasets are all alike, but every messy dataset is messy in its own way.”  Hadley Wickham

&nbsp;

&nbsp;

[@R-for-Data-Science, Kapitel 5 Data tidying]

:::

Häufig werden Daten nicht selbst erstellt, sondern von externen Quellen bezogenen, sodass das Format und der innere Aufbau von Datensätzen nicht selbst bestimmt werden können. Deshalb ist es in der Datenanalyse erforderlich, mit verschiedenen Dateiformaten umgehen zu können: mit wenigen Kilobyte großen Textdateien, proprietären Formaten gängiger Büroanwendungen und mehreren hundert Megabyte großen Dateien in für den Austausch wissenschaftlicher Daten entwickelten Formaten. Programmiersprachen wie Python und R bringen verschiedene Werkzeuge zum Lesen, Bearbeiten und Speichern von verschiedenen Dateiformaten mit, die durch spezialisierte Pakete ergänzt werden können.

Die praktischen Herausforderungen der Datenanalyse beschränken sich jedoch nicht nur auf technische Aspekte. Oftmals bereitet der innere Aufbau von Datensätzen die größten Schwierigkeiten. Dasu und Johnson schreiben: 

::: {.border layout="[[5, 90, 5], [1], [1]]"}

&nbsp;

"Unfortunately, the data set is usually dirty, composed of many tables, and has unknown properties. Before any results can be produced, the data must be cleaned and explored—often a long and
difficult task. [...] In our experience, the tasks of exploratory data mining and data cleaning constitute 80% of the effort that determines 80% of the value of the ultimate data
mining results."

&nbsp;

&nbsp;

([@Dasu-Johnson-2003], S. ix)

:::

Ein wichtiger Bestandteil des Einlesens strukturierter Datensätze besteht deshalb darin, Fehler im Datensatz zu suchen und ggf. zu bereinigen. Unter dem Begriff des Einlesens strukturierter Datensätze wird der gesamte Prozess des Einlesens, der Fehlersuche und -korrektur und des Abspeicherns in für die weitere Bearbeitung geeigneter Form gefasst.

# Grundlagen: Merkmale von Datensätzen
Bevor wir uns mit den praktischen Herausforderungen des Einlesens strukturierter Datensätze beschäftigten, werden zunächst einige Merkmale von Datensätzen diskutiert, um ein grundlegendes Verständnis der Begrifflichkeiten zu schaffen **und den Umgang der in der Basis von Python bzw. R enthaltenen Werkzeuge zu vermitteln**.

::: {#imp-Datensatz .callout-important}
## Datensatz

Ein Datensatz ist eine Sammlung zusammengehöriger Daten. Datensätze enthalten einer oder mehreren Variablen zugeordnete Werte. Jeder Datensatz besitzt ein technisches Format, eine Struktur, mindestens eine Variable und mindestens einen Wert.

:::

### Technisches Format
Das technische Format gibt vor, mit welchen Mitteln Daten eingelesen, bearbeitet und gespeichert werden können. Einige Beispiele sind:

  - Druckerzeugnis, z. B. Telefonbuch: manuelles Ablesen von Name und Telefonnummer, irreversible Bearbeitung per Stift
  
  - Lochkarte, z. B. Parkschein: Lesegerät erkennt Lochung und gewährt eine Freistunde, irreversible Bearbeitung mit Stanzgerät
  
  - Textdatei, z. B. Einwohnerzahl nach Bundesländern: Kann mit einer Vielzahl von Computerprogrammen wie Texteditor, Tabellenkalkulationsprogramm oder Programmierumgebung eingelesen, bearbeitet und gespeichert werden.
  
  - Hierarchical Data Format HDF5, z. B. räumliche Daten zur Blitzdichte: benötigt spezialisierte Programme oder Pakete

### Struktur
Datensätze speichern Daten in einer definierten n-dimensionalen Struktur.

::: {.border}
![n-dimensionale Datensätze](skript/00-bilder/slicing_mf_mp.png){fig-alt="Dargestellt sind von links nach rechts ein-, zwei- und dreidimensionale Blockstrukturen, die Datensätze repräsentieren. Die Teilgrafiken werden in den folgenden Abschnitten wiederverwendet und dabei auch näher beschrieben."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). 2024
:::

#### Eindimensionale Datensätze
Die einfachste Form sind eindimensionale Datensätze, die in einer **Liste** Werte einer einzigen Variablen zuordnen. Eindimensionale Datensätze verfügen lediglich über eine Achse: den Index, über den Elemente angesprochen werden können.

::: {.border}

![eindimensionale Datensätze](skript/00-bilder/eindimensionaler-datensatz-slicing-mf-mp.png){width="50%" fig-alt="Dargestellt ist ein in fünf Blöcke unterteilter Streifen, der einen eindimensionalen Datensatz repräsentiert. Die Blöcke sind entlang der 0. Achse von links nach rechts mit 0 bis 4 beschriftet. Von Block Null aus geht ein blauer Pfeil zu Block drei, der blau markiert ist."}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024
:::

&nbsp;

Beispiele eindimensionaler Datensätze sind ein Einkaufszettel oder die Urliste eines Würfelexperiments. Über den Index kann beispielsweise das Würfelergebnis an der Indexposition 2 ausgegeben werden.

``` {python}
print( *( Augen := [6, 2, 1, 2] ) )

print(f"Das Würfelergebnis an Indexposition 2 lautet: {Augen[2]}")
```


#### Zweidimensionale Datensätze
Zweidimensionale Datensätze organisieren Werte in einer aus Zeilen und Spalten bestehenden **Matrix**.

::: {.border}
![zweidimensionaler Datensatz](skript/00-bilder/zweidimensionaler-datensatz-slicing-mf-mp.png){width="45%" fig-alt=""}

slicing von Marc Fehr ist lizensiert unter [CC-BY-4.0](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen#CC-BY-4.0-1-ov-file) und abrufbar auf [GitHub](https://github.com/bausteine-der-datenanalyse/w-python-numpy-grundlagen). Die Grafik wurde auf den gezeigten Teil beschnitten und die obenstehende Beschriftung entfernt. 2024
:::

Die meisten Datensätze sind zweidimensional. Typischerweise entspricht jede Spalte einer **Variablen**, und jede Zeile einer **Beobachtung**. Variablen speichern alle Werte eines Merkmals, zum Beispiel des Würfelergebnisses. Beobachtungen speichern alle Werte, die für eine Beobachtungseinheit gemessen wurden, z. B. für eine Person. 

``` {python}
import pandas as pd

messung1 = pd.DataFrame({'Name': ['Hans', 'Elke', 'Jean', 'Maya'], 'Geburtstag': ['26.02.', '14.03.', '30.12.', '07.09.'], 'Würfelfarbe': ['rosa', 'rosa', 'blau', 'gelb'], 'Summe Augen': [17, 12, 8, 23]})

messung1
```

Über die Angabe der Indizes entlang der 0. und der 1. Achse kann die Summe der gewürfelten Augen einer Person ausgegeben werden. 

``` {python}

print(f"Jean würfelte {messung1.iloc[2, 3]} Augen")
```

Es ist aber auch möglich, zunächst eine Spalte auszuwählen und dann wie bei einem eindimensionalen Datensatz den Wert an einer Indexposition aufzurufen.

``` {python}

print(f"Jean würfelte {messung1['Summe Augen'][2]} Augen")
```

##### long- und wide-Format
Zweidimensionale Datensätze werden zumeist wie gezeigt in einer aus Zeilen und Spalten bestehenden Matrix dargestellt. Den zeilenweise eingetragenen Beobachtungen werden Werte für die in den Spalten organisierten Variablen zugeordnet. Diese Art Daten darzustellen, wird wide-Format genannt: Mit jeder zusätzlich gemessenen Variablen wird der Datensatz breiter.

Eine andere Art Daten zu organisieren und über Daten nachzudenken ist die Darstellung im long-Format. Schauen wir uns zunächst noch einmal den Datensatz messung1 im wide-Format an. Welche Beobachtungseinheiten gibt es? Welche Variablen wurden für diese erhoben?

``` {python}

messung1
```

Vermutlich werden Sie davon ausgehen, dass die Beobachtungseinheiten Hans, Elke, Jean und Maya sind, für die die Variablen Geburtstag, Würfelfarbe und Summe Augen erhoben wurden. Es ist aber auch denkbar, dass die Beobachtungseinheit Person mit 0, 1, 2 und 3 kodiert wurde (dem Zeilenindex des Datensatzes) und die Spalte Name ebenfalls eine der erhobenen Variablen ist. Ebenso könnte es nur zwei erhobene Merkmale, Würfelfarbe und Summe Augen, geben, während die Spalten Name und Geburtstag die beobachteten Personen kodieren. Stellen Sie sich vor, eine zweite Person mit dem Namen Hans hätte auch gewürfelt. Die Würfelergebnisse der Personen mit dem Namen Hans können nur über den Geburtstag am 26.02. oder 11.11. korrekt zugeordnet werden.

``` {python}
messung1 = pd.DataFrame({'Name': ['Hans', 'Elke', 'Jean', 'Maya', 'Hans'], 'Geburtstag': ['26.02.', '14.03.', '30.12.', '07.09.', '11.11.'], 'Würfelfarbe': ['rosa', 'rosa', 'blau', 'gelb', 'rosa'], 'Summe Augen': [12, 17, 8, 23, 7]})

messung1
```

Das long-Format macht diese Überlegungen explizit, indem identifizierende Variablen (identification variables, kurz: id vars) und gemessene Variablen (measure variables, kurz: measure vars oder value vars) unterschieden werden. Die Transformation eines Datensatzes aus dem wide-Format ins long-Format wird melting (schmelzen) genannt. Dabei wird angegeben, welche Spalten identifizierende Variablen sind. 

``` {python}

messung1_long = pd.melt(messung1, id_vars = ['Name', 'Geburtstag'])

messung1_long
```

Im long-Format werden die gemessenen Variablen in der Spalte variable aufgeführt und deren Wert in der Spalte value eingetragen. Mit jeder zusätzlich erhobenen Variablen wird der Datensatz länger.

Wenn Sie die Unterscheidung von identifizierenden und gemessenen Variablen zu Ende denken, kann der Variablenname selbst als eine identifizierende Variable für die Ausprägung in der Spalte value aufgefasst werden. Ein Datensatz kann als eine Struktur verstanden werden, die genau eine gemessene Variable, nämlich value, und eine Anzahl identifizierender Variablen besitzt. Dies kann im long-Format wie folgt ausgedrückt werden.

``` {python}
#| output: false

messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe'])

messung1_all_id

```

::: {layout="[70, 30]"}
``` {python}
#| echo: false

messung1_all_id = pd.melt(messung1, id_vars = ['Name', 'Geburtstag', 'Würfelfarbe'])

messung1_all_id

```

![](skript/00-bilder/5f489ffabc91dec1ec2192dc4e993e00.jpg){width="60%"}

::: 

Werden beim melting keine id_vars angegeben, werden alle Spalten als gemessene Variablen behandelt.

``` {python}

messung1_no_id = pd.melt(messung1)

messung1_no_id

```

Die Umkehroperation zum melting wird casting (gießen) oder pivoting (schwenken) genannt. Dabei wird ein im long-Format vorliegender Datensatz in das wide-Format konvertiert. 

``` {python}
## pd.pivot() benutzt einen bestehenden Index, den es nicht gibt, deshalb muss man einen reinbasteln.  
## Das ersetzen des bestehenden Index funktioniert nicht, weil der Index sich bei pd.pivot() nicht wiederholen darf
## messung1_no_id.index = list(range(0, 4)) * 5 # geht nicht
## in messung1_no_id eine zusätzliche Spalte für den Index einführen, der für jede Kombination von variable eindeutig ist. Hierfür können wir cumcount aus pandas verwenden, um eine Spalte mit einem laufenden Index für jede variable Gruppierung zu erstellen.

messung1_no_id['ID'] = messung1_no_id.groupby('variable').cumcount()

print (messung1_no_id)

messung1_cast = pd.pivot(messung1_no_id, index = 'ID', columns = 'variable', values = 'value')

print(messung1_cast)

messung1_cast.reset_index(drop = True, inplace = True)


```

melt und cast

Selbst value wird in diesem Sinn zu einer beschreibenden Variablen für die Spalte value.

Unterscheidung von id-variables und gemessene Variablen

Quelle eine andere Art Daten zu organisieren und über Daten nachzudenken




Gar nicht so eindeutig... ist Name unsere Beobachtung oder ist Name eine Variable für die Beobachung 0, 1, 2 und 4?
**ergänzen: long- und wide-Format reshape2**



#### Drei- und mehrdimensionale Datensätze
Datensätze können auch drei- oder mehrdimensional aufgebaut sein.

Mehrdimensional: z. B. Messung an verschiedenen Zeitpunkten oder an verschiedenen Orten
2 Tabellen nebeneinander: Würfelergebnisse und eine Würfelfarbe haben sich geändert



::: {layout-ncol="[50, -10, 50]"}

| Messung 1 | Geburtstag | Würfelfarbe | Summe Augen |
|----|------|------|------|
|  Hans | 26.02. | rosa | 12 |
| Elke | 14.03. | rosa | 22 |
| Jean | 30.12. | blau | 8 |
| Maya | 07.09. | gelb | 17 |

| Messung 2 | Geburtstag | Würfelfarbe | Summe Augen |
|----|------|------|------|
|  Hans | 26.02. | rosa | 14 |
| Elke | 14.03. | rosa | 9 |
| Jean | 30.12. | rosa | 21 |
| Maya | 07.09. | gelb | 13 |

:::

Wir können uns eine vierte Dimension für diese Daten vorstellen, die die Person codiert, die die Messung beaufsichtigt und den Teildatensatz erstellt hat.
Format, Struktur, Variablen, Werte.

Format und Struktur: Unterschied

Kasten Unterschied Format und Struktur, sieht man gut am long- und wide-Format --> potenzielle Begriffskollission zwischen technischem Format und long- und wide-Format

Hinweiskasten zum Unterschied von Format und Struktur
Datensätze unterscheiden sich hinsichtlich ihres Formats (Format unterscheidet sich von Dimensionalität dadurch: Ein dreidimensionaler Datensatz kann in einer Tabellenkalkulation gespeichert in Form einer Matrix (dim = 2) gespeichert werden, die dritte Dimension wird über die Anzahl der Tabellenblätter abgebildet. Es ist aber auch möglich, dreidimensionale Daten in einer einfachen Textdatei zu speichern. data =[ [[1, 2, 3], [2, 3, 1], [3, 2, 1]], [Liegestütze, Kniebeuge, Hock-Streck-Sprünge], [morgens, mittags, abends], [Claus, Petra, Hans]]), ihrer Struktur, d

Zusätzlich B

Tidy Data


Datensätze bestehen aus mindestens einer Variablen, mindestens einem Wert und entweder aus einem Index oder einer Anzahl von Beobachtungen.

Variable, Wert und Beobachtungen ausführen nach Wickham 2014 Tidy Data, S. 3 https://vita.had.co.nz/papers/tidy-data.pdf

Index selbst formulieren: (Wenn Werte keinem Merkmalsträger zugeordnet sind, haben Sie einfach nur einen Index, z. B. Wert an Position 2)



besteht aus mindestens einer Variablen, mindestens einem Wert und können außerdem auch Beobachtungen enthalten. Beobachtungen 



Außerdem 

:::

# Struktur
Datensätze sind Objekte mit einer definierten Struktur. 1-dimensional, 2-dimensional, mehrdimensional

# Datentyp
numerisch, character, factor, boolean, datetime usw. ... 

# Metadaten

# fehlende Werte
nix, NA, NaN, --, -1

masked Arrays

eindimensionaler Datensatz: Urliste von Ergebnissen eines Münzwurfs.
Woraus besteht ein Datensatz?

Dazu gehört die Trennung von Rohdaten, Metadaten, Grafiken und anderer gestalterische Elemente. 

disziplinäre Konventionen und persönliche Vorlieben (z. B. zur Kennzeichnung fehlender oder ungültiger Werte)
ein "NA" führt leicht dazu, dass ein numerischer Datensatz als Zeichenkette erkannt wird.

{{< include _daten-einlesen-mit-python-und-r.md >}}

# Strategien der Fehlersuche und Bereinigung

::: {.border layout="[[5, 90, 5], [1], [1]]"}

&nbsp;

"everybody I know has war stories about cleaning up lousy datasets"  
Nicholas J. Cox

&nbsp;

&nbsp; 

Cox, Nicholas J. 2004: Exploratory Data Mining and Data Cleaning. Book Review 9. In: Journal of Statistical Software 2004, Volume 11. <https://www.jstatsoft.org/article/view/v011b09/30>

:::

# Programme
https://www.heise.de/news/Excel-wandelt-Genbezeichnungen-in-Datumsangaben-um-Problem-groesser-als-gedacht-6165902.html

# Pfade
Dateipfad feststellen (lokal, im Internet), durch Verzeichnisse navigieren 

  * slash / und backslash nach Betriebssystem (Win, Linux, Mac) und Programmiersprache (Python und R)

* Inhalt (gerne abwechslungsreich gestalten)

  * Theorie

  * Beispiele

  * Übungen

# Das Wichtigste (vielleicht als Video)

# Lernzielkontrolle

  * Kompetenzquiz (ggf. aufklappbarer Callout Block, Textverweis für PDF, polierte Lösungen evntl. via Lumi später entscheiden)

  * Übungsaufgaben (kleine Projekte)

* Prüfungsaufgaben (ohne Lösungen)
